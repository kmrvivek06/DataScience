{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def wev2mfcc(file_path, max_pad_length=11):\n",
    "    wave, sr= librosa.load(file_path, mono=True, sr=None)\n",
    "    wave = wave[::3]\n",
    "    mfcc=librosa.feature.mfcc(wave, sr=16000)\n",
    "    pad_width= max_pad_length - mfcc.shape[1]\n",
    "    mfcc=pd.pad(mfcc, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DATA_PATH=\"./data_section5.3/\"\n",
    "def getLabels(path=DATA_PATH):\n",
    "    labels=os.listdir(path)\n",
    "    label_indices = np.arange(0, len(labels))\n",
    "    return labels, label_indices, to_categorical(label_indices)\n",
    "\n",
    "def saveDataToArray(path=DATA_PATH, max_pad_length=11):\n",
    "    labels,_,_=getLabels(path)\n",
    "    \n",
    "    for(label in labels):\n",
    "        mfcc_vector=[]\n",
    "        wav_files=[path+label+'/'+wavfile for wavfile in os.listdir(path+'/'+label)]\n",
    "        for wav_file in wav_files:\n",
    "            mfcc=wev2mfcc(wav_file,max_pad_length=max_pad_length)\n",
    "            mfcc_vector.append(mfcc)\n",
    "        np.save(label+'.npy',mfcc_vector)\n",
    "        \n",
    "from sklearn.model_selection import train_test_split\n",
    "def getTrainTestSplit(split_ratio=0.6, random_state=42):\n",
    "    labels,indices,_ = getLabels(DATA_PATH)\n",
    "    X=np.load(labels[0]+'.npy')\n",
    "    y=np.zeros(x.shape[0])\n",
    "    for i,label in enumerate(labels[1:]):\n",
    "        x=np.load(label+'.npy')\n",
    "        X=np.vstack((X,x))\n",
    "        y=np.append(y,np.full(x_shape[0], fill_value=(i+1)))\n",
    "    assert X.shape[0]==len(y)\n",
    "    return train_test_split(X,y,test_size=(1-split_ratio), random_state=random_state, shuffle=True)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "saveDataToArray()\n",
    "X_train,X_test,y_train,y_test=getTrainTestSplit()\n",
    "X_train=X_train.reshape(X_train.shape[0],20,11,1)\n",
    "X_test=X_test.reshape(X_test.shape[0],20,11,1)\n",
    "y_train_hot=to_categorical(y_train)\n",
    "y_test_hot=to_categorical(y_test)\n",
    "\n",
    "def getModel():\n",
    "    model=Sequential()\n",
    "    model.add(Conv2D(32,kernal_size=(2,2), activation='relu', input_shape=(20,11,1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(3,actiation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=getModel()\n",
    "model.fit(X_train,y_train_hot,batch_size=100,epochs=200,verbose=1,validation_data=(X_test,y_test_hot))\n",
    "\n",
    "def predict(filepath,model):\n",
    "    sample=wev2mfcc(filepath)\n",
    "    sample_reshaped=sample.reshape(1,20,11,1)\n",
    "    return getLabels()[0][np.argmax(model.predict(sample_reshaped))]\n",
    "\n",
    "print(predict('./data_section5.3/cat/1a91fd33_nohash_0.wav',model=model))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
